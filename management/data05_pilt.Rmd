---
title: "Data prep script 5: Cleaning of probabilistic incentive learning task (PILT)-positive and negative"
author: "Brent Rappaport"
date: "`r format(Sys.time(),  '%Y-%m-%d')`"
output:
  pdf_document: default
  html_document:
    df_print: paged
subtitle: Template Rmd
editor_options:
  chunk_output_type: console
toc: yes
---

# About
This script preprocesses behavioral data from the probabilistic incentive learning task (PILT). The data are cleaned, removing trials with extremely slow/fast reaction times (<150ms or >2500ms).
In addition to an overall measure of reward bias and loss avoidance in each of the two blocks of the PILT, this script also caculates the reward bias and loss avoidance for those trials within specific reaction time quantiles. This allows one to additionally examine whether reward bias/loss avoidance differed as a function of reaction time.

# 1. Get Setup
## 1.1. Clear everything & set width
```{r echo=TRUE, results='hide', message=FALSE}
    options(width=80) #Set width
    rm(list=ls())     #Remove everything from environment
    cat("\014")       #Clear Console
```

## 1.2. Load Libraries
```{r echo=TRUE, results='hide', message=FALSE}
  # renv::restore()     #restore environment
  library(knitr)      #allows rmarkdown files
  library(haven)      #helps import stata
  library(questionr)  #allows lookfor function
  library(tidyverse)  #plotting/cleaning, etc.
  library(broom)      #nice statistical output
  library(here)       #nice file paths
  library(expss)      #labeling variables/values
  library(psych)      #used for statistical analyses
  library(ggplot2)    #creates plots
  library(irr)        #ICC
  library(readxl)     #read excel files
  library(workflowr)  #helps with workflow
```

## 1.3. Get the Working Directory
```{r}
  here()
```

## 1.4. Set seed
   Remember to set your seed AFTER you load libraries
```{r}
     set.seed(314)    #Set seed
```

## 1.5 Load Data
Remember to immediately rename and remove. Avoid overwriting old data.
```{r}
PILTP_data <- read_excel("../_rawdata/pilt_behavioral/T20/FP_all_T20.xlsx")
piltp_data <- PILTP_data; rm(PILTP_data)

PILTN_data <- read_excel("../_rawdata/pilt_behavioral/T20/FN_all_T20.xlsx")
piltn_data <- PILTN_data; rm(PILTN_data)
```

## 2. Clean PILT-P and PILT-N
### 2.1. PILT-P
```{r}
piltp_data$Subid <- as.numeric(piltp_data$Subject)
length(unique(piltp_data$Subid))

piltp_data$Block <- piltp_data$Block-1
# Take log of reaction time to use later in Quality Control
piltp_data$log_Mouth.RT <- log(piltp_data$Mouth.RT)

# Per Quality Control, calculate values to use to flag outliers
piltp_outliercount <-piltp_data %>% 
  dplyr::group_by(Subid,Block) %>% 
  dplyr::summarise(BadTrials=sum(Mouth.RT<150 | Mouth.RT>2500)+sum(log_Mouth.RT>(mean(log_Mouth.RT)+3*sd(log_Mouth.RT)) | log_Mouth.RT<(mean(log_Mouth.RT)-3*sd(log_Mouth.RT))),
                   GoodTrials=60-BadTrials,
                   Rich=sum(CurrentTrialRCStatus=="RewardCondition"), 
                   Lean=sum(CurrentTrialRCStatus=="NotRewardCondition"),
                   Rich_reward=sum(CurrentTrialRCStatus == "RewardCondition" & FeedbackActiveState == "CorrectWin"),
                   Lean_reward=sum(CurrentTrialRCStatus == "NotRewardCondition" & FeedbackActiveState == "CorrectWin"),
                   Rich_nofb=sum(CurrentTrialRCStatus == "RewardCondition" & FeedbackActiveState == "NoFeedback"),
                   Lean_nofb=sum(CurrentTrialRCStatus == "NotRewardCondition" & FeedbackActiveState == "NoFeedback"),
                   RL_reward_ratio=Rich_reward/Lean_reward,
                   Accuracy=sum(CRESP==1)/60)


# Filter out extreme trials based on reaction time
piltp_data_clean <- piltp_data %>%
  dplyr::filter(Mouth.RT>150 & Mouth.RT<2500) %>%
  dplyr::group_by(Subid) %>% 
  dplyr::filter(log_Mouth.RT<(mean(log_Mouth.RT)+3*sd(log_Mouth.RT)) & 
                log_Mouth.RT>(mean(log_Mouth.RT)-3*sd(log_Mouth.RT)))
  
# Filter out extreme subjects
# piltp_data_participantstokeep <- piltp_outliercount %>%
#   dplyr::filter(GoodTrials >= 48 & 
#                 Rich_reward >= 15 & 
#                 Lean_reward >= 5 & 
#                 RL_reward_ratio >= 2.5 & 
#                 Accuracy >= 0.40000000) %>%
#   dplyr::filter(Subid, n()>1)
# piltp_data_cleaned <- piltp_data_clean %>% 
#   dplyr::semi_join(piltp_data_participantstokeep, by = "Subid") %>%
#   dplyr::arrange(Subid)

# Calculate accuracy
piltp_data_cleaned <- piltp_data_clean %>%
  dplyr::group_by(Subid,Block) %>% 
  dplyr::mutate(Accuracy=sum(CRESP==1)/60)

# Check to make sure the correct subjects are kept
# length(unique(piltp_data_participantstokeep$Subid)) == length(unique(piltp_data_cleaned$Subid)) #should be TRUE
# cor(unique(piltp_data_participantstokeep$Subid),unique(piltp_data_cleaned$Subid)) #should be 1
```

### 2.2. PILT-N
```{r}
piltn_data$Subid <- as.numeric(piltn_data$Subject)
length(unique(piltn_data$Subid))

piltn_data$Block <- piltn_data$Block-1
# Take log of reaction time to use later in Quality Control
piltn_data$log_Mouth.RT <- log(piltn_data$Mouth.RT)

# Per Quality Control, calculate values to use to flag outliers
piltn_outliercount <-piltn_data %>% 
  dplyr::group_by(Subid,Block) %>% 
  dplyr::summarise(BadTrials=sum(Mouth.RT<150 | Mouth.RT>2500)+sum(log_Mouth.RT>(mean(log_Mouth.RT)+3*sd(log_Mouth.RT)) | log_Mouth.RT<(mean(log_Mouth.RT)-3*sd(log_Mouth.RT))),
                   GoodTrials=60-BadTrials,
                   Rich=sum(CurrentTrialRCStatus=="RewardCondition"), 
                   Lean=sum(CurrentTrialRCStatus=="NotRewardCondition"),
                   Rich_reward=sum(CurrentTrialRCStatus == "RewardCondition" & FeedbackActiveState == "SorryLose"),
                   Lean_reward=sum(CurrentTrialRCStatus == "NotRewardCondition" & FeedbackActiveState == "SorryLose"),
                   Rich_nofb=sum(CurrentTrialRCStatus == "RewardCondition" & FeedbackActiveState == "NoFeedback"),
                   Lean_nofb=sum(CurrentTrialRCStatus == "NotRewardCondition" & FeedbackActiveState == "NoFeedback"),
                   RL_reward_ratio=Rich_reward/Lean_reward,
                   Accuracy=sum(CRESP==0)/60)


# Filter out extreme trials based on reaction time
piltn_data_clean <- piltn_data %>%
  dplyr::filter(Mouth.RT>150 & Mouth.RT<2500) %>%
  dplyr::group_by(Subid) %>% 
  dplyr::filter(log_Mouth.RT<(mean(log_Mouth.RT)+3*sd(log_Mouth.RT)) & 
                log_Mouth.RT>(mean(log_Mouth.RT)-3*sd(log_Mouth.RT)))


# hist(piltn_outliercount$GoodTrials); table(piltn_outliercount$GoodTrials>=48)/2
# hist(piltn_outliercount$Rich_reward); table(piltn_outliercount$Rich_reward>=5)/2
# hist(piltn_outliercount$Lean_reward); table(piltn_outliercount$Lean_reward>=2)/2
# hist(piltn_outliercount$RL_reward_ratio); table(piltn_outliercount$RL_reward_ratio>=2.5)/2
# hist(piltn_outliercount$Accuracy); table(piltn_outliercount$Accuracy>=0.4)/2

# Filter out extreme subjects
# piltn_data_participantstokeep <- piltn_outliercount %>%
#   dplyr::filter(GoodTrials >= 48 & 
#                 Rich_reward >= 5 & 
#                 Lean_reward >= 2 & 
#                 RL_reward_ratio >= 2.5 & 
#                 Accuracy >= 0.40000000) %>%
#   dplyr::filter(Subid, n()>1)
# piltn_data_cleaned <- piltn_data_clean %>% 
#   dplyr::semi_join(piltn_data_participantstokeep, by = "Subid") %>%
#   dplyr::arrange(Subid)

# Calculate accuracy
piltn_data_cleaned <- piltn_data_clean %>%
  dplyr::group_by(Subid,Block) %>% 
  dplyr::mutate(Accuracy=sum(CRESP==0)/60)

# Check to make sure the correct subjects are kept
# length(unique(piltn_data_participantstokeep$Subid)) == length(unique(piltn_data_cleaned$Subid)) #should be TRUE
# cor(unique(piltn_data_participantstokeep$Subid),unique(piltn_data_cleaned$Subid)) #should be 1
```


## 3. Calculate reward bias and loss avoidance
### 3.1. Reward bias
```{r}
# Create quantiles and label trials
piltp_quantile_list <- as.data.frame(quantile(piltp_data_cleaned$Mouth.RT, probs=c(0.005,0.1,0.3,0.5,0.7,0.9,0.995)))
piltp_data_quantiles <- piltp_data_cleaned %>%
  dplyr::mutate(quantiles = case_when(
                           Mouth.RT <= piltp_quantile_list[1,1] ~ 0.005,
                           Mouth.RT <= piltp_quantile_list[2,1] & Mouth.RT > piltp_quantile_list[1,1] ~ 0.1,
                           Mouth.RT <= piltp_quantile_list[3,1] & Mouth.RT > piltp_quantile_list[2,1] ~ 0.3,
                           Mouth.RT <= piltp_quantile_list[4,1] & Mouth.RT > piltp_quantile_list[3,1] ~ 0.5,
                           Mouth.RT <= piltp_quantile_list[5,1] & Mouth.RT > piltp_quantile_list[4,1] ~ 0.7,
                           Mouth.RT <= piltp_quantile_list[6,1] & Mouth.RT > piltp_quantile_list[5,1] ~ 0.9,
                           Mouth.RT <= piltp_quantile_list[7,1] & Mouth.RT > piltp_quantile_list[6,1] ~ 0.995))
piltp_data_quantiles$quantiles <- as.factor(piltp_data_quantiles$quantiles)

piltp_data_cleaned$Block <- dplyr::recode(piltp_data_cleaned$Block, `1`="block1", `2`="block2")

piltp_data_RB1 <-piltp_data_cleaned %>%
  group_by(Subid,Block) %>%
            # For all quantiles
  summarise(Rich_Correct_20 = sum(CurrentTrialRCStatus == "RewardCondition" & CRESP == 1)+0.5,
            Rich_Incorrect_20 = sum(CurrentTrialRCStatus == "RewardCondition" & CRESP == 0)+0.5,
            Lean_Correct_20 = sum(CurrentTrialRCStatus == "NotRewardCondition" & CRESP == 1)+0.5,
            Lean_Incorrect_20 = sum(CurrentTrialRCStatus == "NotRewardCondition" & CRESP == 0)+0.5,
            N_trials = length(Mouth.RT),
            # For the first two quantiles
            Rich_Correct_20_12quant = sum(CurrentTrialRCStatus == "RewardCondition" & CRESP == 1 & 
                                         Mouth.RT <= piltp_quantile_list[3,1] & Mouth.RT > piltp_quantile_list[1,1])+0.5,
            Rich_Incorrect_20_12quant = sum(CurrentTrialRCStatus == "RewardCondition" & CRESP == 0 & 
                                         Mouth.RT <= piltp_quantile_list[3,1] & Mouth.RT > piltp_quantile_list[1,1])+0.5,
            Lean_Correct_20_12quant = sum(CurrentTrialRCStatus == "NotRewardCondition" & CRESP == 1 & 
                                         Mouth.RT <= piltp_quantile_list[3,1] & Mouth.RT > piltp_quantile_list[1,1])+0.5,
            Lean_Incorrect_20_12quant = sum(CurrentTrialRCStatus == "NotRewardCondition" & CRESP == 0 & 
                                         Mouth.RT <= piltp_quantile_list[3,1] & Mouth.RT > piltp_quantile_list[1,1])+0.5,
            N_trials_12quant = length(which(Mouth.RT <= piltp_quantile_list[3,1] & Mouth.RT > piltp_quantile_list[1,1])),
            # For the first three quantiles
            Rich_Correct_20_123quant = sum(CurrentTrialRCStatus == "RewardCondition" & CRESP == 1 & 
                                         Mouth.RT <= piltp_quantile_list[4,1] & Mouth.RT > piltp_quantile_list[1,1])+0.5,
            Rich_Incorrect_20_123quant = sum(CurrentTrialRCStatus == "RewardCondition" & CRESP == 0 & 
                                         Mouth.RT <= piltp_quantile_list[4,1] & Mouth.RT > piltp_quantile_list[1,1])+0.5,
            Lean_Correct_20_123quant = sum(CurrentTrialRCStatus == "NotRewardCondition" & CRESP == 1 & 
                                         Mouth.RT <= piltp_quantile_list[4,1] & Mouth.RT > piltp_quantile_list[1,1])+0.5,
            Lean_Incorrect_20_123quant = sum(CurrentTrialRCStatus == "NotRewardCondition" & CRESP == 0 & 
                                         Mouth.RT <= piltp_quantile_list[4,1] & Mouth.RT > piltp_quantile_list[1,1])+0.5,
            N_trials_123quant = length(which(Mouth.RT <= piltp_quantile_list[4,1] & Mouth.RT > piltp_quantile_list[1,1])),
            
            # For the first four quantiles
            Rich_Correct_20_1234quant = sum(CurrentTrialRCStatus == "RewardCondition" & CRESP == 1 & 
                                         Mouth.RT <= piltp_quantile_list[5,1] & Mouth.RT > piltp_quantile_list[1,1])+0.5,
            Rich_Incorrect_20_1234quant = sum(CurrentTrialRCStatus == "RewardCondition" & CRESP == 0 & 
                                         Mouth.RT <= piltp_quantile_list[5,1] & Mouth.RT > piltp_quantile_list[1,1])+0.5,
            Lean_Correct_20_1234quant = sum(CurrentTrialRCStatus == "NotRewardCondition" & CRESP == 1 & 
                                         Mouth.RT <= piltp_quantile_list[5,1] & Mouth.RT > piltp_quantile_list[1,1])+0.5,
            Lean_Incorrect_20_1234quant = sum(CurrentTrialRCStatus == "NotRewardCondition" & CRESP == 0 & 
                                         Mouth.RT <= piltp_quantile_list[5,1] & Mouth.RT > piltp_quantile_list[1,1])+0.5,
            N_trials_1234quant = length(which(Mouth.RT <= piltp_quantile_list[4,1] & Mouth.RT > piltp_quantile_list[1,1])))

CLEAN_piltp_data <- piltp_data_RB1 %>%
  mutate(Reward_bias_20 = (log((Rich_Correct_20*Lean_Incorrect_20)/(Rich_Incorrect_20*Lean_Correct_20)))*.5,
         Reward_bias_20_12quant = (log((Rich_Correct_20_12quant*Lean_Incorrect_20_12quant)/(Rich_Incorrect_20_12quant*Lean_Correct_20_12quant)))*.5,
         Reward_bias_20_123quant = (log((Rich_Correct_20_123quant*Lean_Incorrect_20_123quant)/(Rich_Incorrect_20_123quant*Lean_Correct_20_123quant)))*.5,
         Reward_bias_20_1234quant = (log((Rich_Correct_20_1234quant*Lean_Incorrect_20_1234quant)/(Rich_Incorrect_20_1234quant*Lean_Correct_20_1234quant)))*.5,
         PILTP_Disc_20 = (log((Rich_Correct_20*Lean_Correct_20)/(Rich_Incorrect_20*Lean_Incorrect_20)))*.5) %>%
  
  pivot_wider(id_cols="Subid", names_from="Block", values_from=c("Reward_bias_20","Reward_bias_20_12quant","Reward_bias_20_123quant","Reward_bias_20_1234quant","PILTP_Disc_20"))

# Make infinite values NA
CLEAN_piltp_data[mapply(is.infinite, CLEAN_piltp_data)] <- NA
#Calculate mean across blocks
CLEAN_piltp_data$Reward_bias_20 <- rowMeans(CLEAN_piltp_data[,c("Reward_bias_20_block1","Reward_bias_20_block2")], na.rm=TRUE)
CLEAN_piltp_data$PILTP_Disc_20 <- rowMeans(CLEAN_piltp_data[,c("PILTP_Disc_20_block1","PILTP_Disc_20_block2")], na.rm=TRUE)

# Count number of subjects with data for each reward bias
apply(CLEAN_piltp_data[,-1], 2, function(x) sum(!is.na(x)))
```

### 3.2. Loss avoidance
```{r}
# Create quantiles and label trials
piltn_quantile_list <- as.data.frame(quantile(piltn_data_cleaned$Mouth.RT, probs=c(0.005,0.1,0.3,0.5,0.7,0.9,0.995)))
piltn_data_quantiles <- piltn_data_cleaned %>%
  dplyr::mutate(quantiles = case_when(
                           Mouth.RT <= piltn_quantile_list[1,1] ~ 0.005,
                           Mouth.RT <= piltn_quantile_list[2,1] & Mouth.RT > piltn_quantile_list[1,1] ~ 0.1,
                           Mouth.RT <= piltn_quantile_list[3,1] & Mouth.RT > piltn_quantile_list[2,1] ~ 0.3,
                           Mouth.RT <= piltn_quantile_list[4,1] & Mouth.RT > piltn_quantile_list[3,1] ~ 0.5,
                           Mouth.RT <= piltn_quantile_list[5,1] & Mouth.RT > piltn_quantile_list[4,1] ~ 0.7,
                           Mouth.RT <= piltn_quantile_list[6,1] & Mouth.RT > piltn_quantile_list[5,1] ~ 0.9,
                           Mouth.RT <= piltn_quantile_list[7,1] & Mouth.RT > piltn_quantile_list[6,1] ~ 0.995))
piltn_data_quantiles$quantiles <- as.factor(piltn_data_quantiles$quantiles)

piltn_data_cleaned$Block <- dplyr::recode(piltn_data_cleaned$Block, `1`="block1", `2`="block2")

piltn_data_RB1 <-piltn_data_cleaned %>%
  group_by(Subid,Block) %>%
            # For all quantiles
  summarise(Rich_Correct_20 = sum(CurrentTrialRCStatus == "RewardCondition" & CRESP == 0)+0.5,
            Rich_Incorrect_20 = sum(CurrentTrialRCStatus == "RewardCondition" & CRESP == 1)+0.5,
            Lean_Correct_20 = sum(CurrentTrialRCStatus == "NotRewardCondition" & CRESP == 0)+0.5,
            Lean_Incorrect_20 = sum(CurrentTrialRCStatus == "NotRewardCondition" & CRESP == 1)+0.5,
            N_trials = length(Mouth.RT),
            # For the first two quantiles
            Rich_Correct_20_12quant = sum(CurrentTrialRCStatus == "RewardCondition" & CRESP == 0 & 
                                         Mouth.RT <= piltn_quantile_list[3,1] & Mouth.RT > piltn_quantile_list[1,1])+0.5,
            Rich_Incorrect_20_12quant = sum(CurrentTrialRCStatus == "RewardCondition" & CRESP == 1 & 
                                         Mouth.RT <= piltn_quantile_list[3,1] & Mouth.RT > piltn_quantile_list[1,1])+0.5,
            Lean_Correct_20_12quant = sum(CurrentTrialRCStatus == "NotRewardCondition" & CRESP == 0 & 
                                         Mouth.RT <= piltn_quantile_list[3,1] & Mouth.RT > piltn_quantile_list[1,1])+0.5,
            Lean_Incorrect_20_12quant = sum(CurrentTrialRCStatus == "NotRewardCondition" & CRESP == 1 & 
                                         Mouth.RT <= piltn_quantile_list[3,1] & Mouth.RT > piltn_quantile_list[1,1])+0.5,
            N_trials_12quant = length(which(Mouth.RT <= piltn_quantile_list[3,1] & Mouth.RT > piltn_quantile_list[1,1])),
            # For the first three quantiles
            Rich_Correct_20_123quant = sum(CurrentTrialRCStatus == "RewardCondition" & CRESP == 0 & 
                                         Mouth.RT <= piltn_quantile_list[4,1] & Mouth.RT > piltn_quantile_list[1,1])+0.5,
            Rich_Incorrect_20_123quant = sum(CurrentTrialRCStatus == "RewardCondition" & CRESP == 1 & 
                                         Mouth.RT <= piltn_quantile_list[4,1] & Mouth.RT > piltn_quantile_list[1,1])+0.5,
            Lean_Correct_20_123quant = sum(CurrentTrialRCStatus == "NotRewardCondition" & CRESP == 0 & 
                                         Mouth.RT <= piltn_quantile_list[4,1] & Mouth.RT > piltn_quantile_list[1,1])+0.5,
            Lean_Incorrect_20_123quant = sum(CurrentTrialRCStatus == "NotRewardCondition" & CRESP == 1 & 
                                         Mouth.RT <= piltn_quantile_list[4,1] & Mouth.RT > piltn_quantile_list[1,1])+0.5,
            N_trials_123quant = length(which(Mouth.RT <= piltn_quantile_list[4,1] & Mouth.RT > piltn_quantile_list[1,1])),
            
            # For the first four quantiles
            Rich_Correct_20_1234quant = sum(CurrentTrialRCStatus == "RewardCondition" & CRESP == 0 & 
                                         Mouth.RT <= piltn_quantile_list[5,1] & Mouth.RT > piltn_quantile_list[1,1])+0.5,
            Rich_Incorrect_20_1234quant = sum(CurrentTrialRCStatus == "RewardCondition" & CRESP == 1 & 
                                         Mouth.RT <= piltn_quantile_list[5,1] & Mouth.RT > piltn_quantile_list[1,1])+0.5,
            Lean_Correct_20_1234quant = sum(CurrentTrialRCStatus == "NotRewardCondition" & CRESP == 0 & 
                                         Mouth.RT <= piltn_quantile_list[5,1] & Mouth.RT > piltn_quantile_list[1,1])+0.5,
            Lean_Incorrect_20_1234quant = sum(CurrentTrialRCStatus == "NotRewardCondition" & CRESP == 1 & 
                                         Mouth.RT <= piltn_quantile_list[5,1] & Mouth.RT > piltn_quantile_list[1,1])+0.5,
            N_trials_1234quant = length(which(Mouth.RT <= piltn_quantile_list[4,1] & Mouth.RT > piltn_quantile_list[1,1])))

CLEAN_piltn_data <- piltn_data_RB1 %>%
  mutate(Loss_bias_20 = (log((Rich_Correct_20*Lean_Incorrect_20)/(Rich_Incorrect_20*Lean_Correct_20)))*.5,
         Loss_bias_20_12quant = (log((Rich_Correct_20_12quant*Lean_Incorrect_20_12quant)/(Rich_Incorrect_20_12quant*Lean_Correct_20_12quant)))*.5,
         Loss_bias_20_123quant = (log((Rich_Correct_20_123quant*Lean_Incorrect_20_123quant)/(Rich_Incorrect_20_123quant*Lean_Correct_20_123quant)))*.5,
         Loss_bias_20_1234quant = (log((Rich_Correct_20_1234quant*Lean_Incorrect_20_1234quant)/(Rich_Incorrect_20_1234quant*Lean_Correct_20_1234quant)))*.5,
         PILTN_Disc_20 = (log((Rich_Correct_20*Lean_Correct_20)/(Rich_Incorrect_20*Lean_Incorrect_20)))*.5) %>%
  
  pivot_wider(id_cols="Subid", names_from="Block", values_from=c("Loss_bias_20","Loss_bias_20_12quant","Loss_bias_20_123quant","Loss_bias_20_1234quant","PILTN_Disc_20"))

# Make infinite values NA
CLEAN_piltn_data[mapply(is.infinite, CLEAN_piltn_data)] <- NA
#Calculate mean across blocks
CLEAN_piltn_data$Loss_bias_20 <- rowMeans(CLEAN_piltn_data[,c("Loss_bias_20_block1","Loss_bias_20_block2")], na.rm=TRUE)
CLEAN_piltn_data$PILTN_Disc_20 <- rowMeans(CLEAN_piltn_data[,c("PILTN_Disc_20_block1","PILTN_Disc_20_block2")], na.rm=TRUE)

# Count number of subjects with data for each measure
apply(CLEAN_piltn_data[,-1], 2, function(x) sum(!is.na(x)))
```

# 4. Split-half reliability
```{r}
splithalf_p <- piltp_data_cleaned %>%
  mutate(ind = rep(c(1, 2),length.out = n())) %>%
  group_by(Subid,ind) %>%
  summarise(Rich_Correct_20 = sum(CurrentTrialRCStatus == "RewardCondition" & CRESP == 0)+0.5,
            Rich_Incorrect_20 = sum(CurrentTrialRCStatus == "RewardCondition" & CRESP == 1)+0.5,
            Lean_Correct_20 = sum(CurrentTrialRCStatus == "NotRewardCondition" & CRESP == 0)+0.5,
            Lean_Incorrect_20 = sum(CurrentTrialRCStatus == "NotRewardCondition" & CRESP == 1)+0.5) %>%
  pivot_wider(names_from=ind, values_from=(c("Rich_Correct_20","Rich_Incorrect_20","Lean_Correct_20","Lean_Incorrect_20"))) %>%
  mutate(Reward_bias_20_1 = log((Rich_Correct_20_1*Lean_Incorrect_20_1)/(Rich_Incorrect_20_1*Lean_Correct_20_1))*.5,
         Reward_bias_20_2 = log((Rich_Correct_20_2*Lean_Incorrect_20_2)/(Rich_Incorrect_20_2*Lean_Correct_20_2))*.5,)

splithalf_n <- piltn_data_cleaned %>%
  mutate(ind = rep(c(1, 2),length.out = n())) %>%
  group_by(Subid,ind) %>%
  summarise(Rich_Correct_20 = sum(CurrentTrialRCStatus == "RewardCondition" & CRESP == 0)+0.5,
            Rich_Incorrect_20 = sum(CurrentTrialRCStatus == "RewardCondition" & CRESP == 1)+0.5,
            Lean_Correct_20 = sum(CurrentTrialRCStatus == "NotRewardCondition" & CRESP == 0)+0.5,
            Lean_Incorrect_20 = sum(CurrentTrialRCStatus == "NotRewardCondition" & CRESP == 1)+0.5) %>%
  pivot_wider(names_from=ind, values_from=(c("Rich_Correct_20","Rich_Incorrect_20","Lean_Correct_20","Lean_Incorrect_20"))) %>%
  mutate(Loss_bias_20_1 = log((Rich_Correct_20_1*Lean_Incorrect_20_1)/(Rich_Incorrect_20_1*Lean_Correct_20_1))*.5,
         Loss_bias_20_2 = log((Rich_Correct_20_2*Lean_Incorrect_20_2)/(Rich_Incorrect_20_2*Lean_Correct_20_2))*.5,)
```

# 5. Merge data
```{r}
DISS_cleaning05_pilt <- full_join(CLEAN_piltp_data, CLEAN_piltn_data, by="Subid")
```


# 6. Save Data
```{r}
save(DISS_cleaning05_pilt, file="./data/DISS_cleaning05_pilt.RData")

save(splithalf_p, splithalf_n, file="./data/DISS_splithalf_pilt.RData")

sum(!is.na(DISS_cleaning05_pilt$Reward_bias_20))
sum(!is.na(DISS_cleaning05_pilt$Loss_bias_20))
```

# 7. Closing out
  In this step, go ahead and close out of the file and quit R without saving  
  the work space.
```{r}
   renv::snapshot()   #Take a snapshot of environment
```
